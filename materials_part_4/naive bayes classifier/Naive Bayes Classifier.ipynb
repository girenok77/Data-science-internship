{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived       0\n",
      "Pclass         3\n",
      "Sex         male\n",
      "Age           22\n",
      "SibSp          1\n",
      "Parch          0\n",
      "Fare        7.25\n",
      "Embarked       S\n",
      "Name: 0, dtype: object \n",
      "\n",
      "Pclass          3.00\n",
      "Sex             0.00\n",
      "Age            22.00\n",
      "SibSp           1.00\n",
      "Parch           0.00\n",
      "Fare            7.25\n",
      "Cherbourg       0.00\n",
      "Queenstown      0.00\n",
      "Southampton     1.00\n",
      "survive         0.00\n",
      "Name: 0, dtype: float64\n",
      "datatype <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# titanic survive\n",
    "df = pd.read_csv('titanic.csv',header=0,usecols=['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','Survived'])\n",
    "df= df.dropna(axis=0)\n",
    "y=df.iloc[:,0]\n",
    "print(df.iloc[0,:],'\\n')\n",
    "#replace strings values to numeric\n",
    "df['Sex'] = df['Sex'].map({'female': 1, 'male': 0})\n",
    "\n",
    "df['Cherbourg'] =   df['Embarked'].map({'C' : 1, 'Q':0, 'S':0})\n",
    "df['Queenstown'] =  df['Embarked'].map({'C' : 0, 'Q':1, 'S':0})\n",
    "df['Southampton'] = df['Embarked'].map({'C' : 0, 'Q':0, 'S':1})\n",
    "\n",
    "df = df.drop(['Survived','Embarked'], axis=1)\n",
    "df[\"survive\"]=y\n",
    "\n",
    "print(df.iloc[0,:])\n",
    "\n",
    "dataset = df.values\n",
    "splitRatio = 0.67\n",
    "print(\"datatype\",type(dataset))\n",
    "trainSize = int(dataset.shape[0] * splitRatio)\n",
    "\n",
    "\n",
    "# for i in np.arange(x11.shape[0]):\n",
    "#     if x11[i,0]=='female':\n",
    "#         x11[i,0]=0.\n",
    "#     else:\n",
    "#         x11[i,0]=1.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadCsv():\n",
    "    # titanic survive\n",
    "    df = pd.read_csv('titanic.csv',header=0,usecols=['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','Survived'])\n",
    "    df= df.dropna(axis=0)\n",
    "    y=df.iloc[:,0]\n",
    "    #replace strings values to numeric\n",
    "    df['Sex'] = df['Sex'].map({'female': 1, 'male': 0})\n",
    "\n",
    "    df['Cherbourg'] =   df['Embarked'].map({'C' : 1, 'Q':0, 'S':0})\n",
    "    df['Queenstown'] =  df['Embarked'].map({'C' : 0, 'Q':1, 'S':0})\n",
    "    df['Southampton'] = df['Embarked'].map({'C' : 0, 'Q':0, 'S':1})\n",
    "\n",
    "    df = df.drop(['Survived','Embarked'], axis=1)\n",
    "    df[\"survive\"]=y\n",
    "\n",
    "    dataset = df.values\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitDataset(dataset, splitRatio):\n",
    "    # Training set size\n",
    "    trainSize = int(dataset.shape[0] * splitRatio)\n",
    "    \n",
    "    # List of randomly chosen indicies\n",
    "    indices = np.random.permutation(dataset.shape[0])\n",
    "    \n",
    "    # Split indicies for training and test set by trainSize\n",
    "    training_idx, test_idx = indices[:trainSize], indices[trainSize:]\n",
    "    \n",
    "    # Create training and test sets by indicies\n",
    "    training, test = dataset[training_idx,:], dataset[test_idx,:]\n",
    "    \n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateByClass(dataset):\n",
    "    # Here we limit our classes to 0 and 1\n",
    "    # You need to generalize this for arbitrary number of classes\n",
    "    ones = dataset[np.where(dataset[:, -1]==1), :]\n",
    "    zeros = dataset[np.where(dataset[:, -1]==0), :]\n",
    "    \n",
    "    p_ones_prob = ones.shape[1] / dataset.shape[0]\n",
    "    p_zeros_prob = zeros.shape[1] / dataset.shape[0]\n",
    "    \n",
    "    return {\n",
    "        1: (ones, p_ones_prob),\n",
    "        0: (zeros, p_zeros_prob)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarize(dataset):\n",
    "    # Calculate means and standart deviations with one degree of freedom for each attribute\n",
    "    # We do it by column which is axis 1\n",
    "    # Also we remove last elements (guess why?)\n",
    "    means = dataset[0].mean(axis=1)[0][:-1]\n",
    "    stds  = dataset[0].std(axis=1, ddof=1)[0][:-1]\n",
    "    p_c = dataset[1]\n",
    "    \n",
    "    # Think what we do here?\n",
    "    return means, stds, p_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarizeByClass(dataset):\n",
    "    # Divide dataset by class and summarize it\n",
    "    separated = separateByClass(dataset)\n",
    "    \n",
    "    summaries = {}\n",
    "    \n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    \n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProbability(x, mean, stdev):\n",
    "    # Calculate probability by x, mean and std\n",
    "    # 1/(sqrt(2pi)*std)*exp(-(x-mean)^2/(2std^2))\n",
    "    return np.exp(-(x - mean)**2/(2 * stdev**2)) / (np.sqrt(2 * np.pi) * stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    # Calculate probabilities for input vector from test set\n",
    "    probabilities = {}\n",
    "    \n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        \n",
    "        means = classSummaries[0]\n",
    "        stds  = classSummaries[1]\n",
    "        p_c   = classSummaries[2]\n",
    "        \n",
    "        # Calculate corresonding probabilities and multiply them\n",
    "        probabilities[classValue] = np.prod(calculateProbability(inputVector[:-1], means, stds)) * p_c\n",
    "\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(summaries, inputVector):\n",
    "    # Calculate probabilities\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    \n",
    "    # Init values of probability and label\n",
    "    bestLabel, bestProb = None, -1\n",
    "    \n",
    "    # Check probability of which class is better\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    \n",
    "    return bestLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPredictions(summaries, testSet):\n",
    "    # For each probability find optimal labels\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    # Check accuracy\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Set split ratio\n",
    "    splitRatio = 0.09\n",
    "    \n",
    "    # Load dataset and return numpy array\n",
    "    dataset = loadCsv()\n",
    "    \n",
    "    # Split dataset\n",
    "    trainingSet, testSet = splitDataset(dataset, splitRatio)\n",
    "    \n",
    "    # Log row amounts\n",
    "    print('Split {0} rows into train={1} and test={2} rows'.format(len(dataset), len(trainingSet), len(testSet)))\n",
    "    \n",
    "    # Prepare model\n",
    "    summaries = summarizeByClass(trainingSet)\n",
    "    \n",
    "    # Test model\n",
    "    predictions = getPredictions(summaries, testSet)\n",
    "    \n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    \n",
    "    print('Accuracy: {0}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 712 rows into train=64 and test=648 rows\n",
      "Accuracy: 76.08024691358025%\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
